{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the neccessary libs\n",
    "import os\n",
    "import numpy as np \n",
    "import librosa\n",
    "import hmmlearn.hmm as hmm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Step 1: Collect a dataset of audio recordings of each command to recognize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial 1: Error: We end up with a directory instead of a file when executing the for commans in commands\n",
    "#                 loop: therefore, we used an alternative folder with few datasamples in a single dir\n",
    "\n",
    "\n",
    "# dataset_path = \"/home/ix502iv/Documents/Audio_Trad/HMM/custom_commands\" # use absolute path\n",
    "# commands = [\"demo_fider_ac\", \"demo_fider_bilgileri\", \"demo_fider_kapat\", \"nem_durumu\", \"gsm_durumu\"]\n",
    "# dataset = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trial 2 : made use of a new dataset with very little data smaples\n",
    "\n",
    "dataset_path = \"/home/ix502iv/Documents/Audio_Trad/HMM/custom_commands_copy\" # use absolute path\n",
    "commands = [\"demo_fider_ac\", \"demo_fider_bilgileri\", \"demo_fider_kapat\", \"nem_durumu\", \"gsm_durumu\"]\n",
    "dataset = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['demo_fider_ac.wav']\n",
      "['demo_fider_bilgileri.wav']\n",
      "['demo_fider_kapat.wav']\n",
      "['nem_durumu.wav']\n",
      "['gsm_durumu.wav']\n"
     ]
    }
   ],
   "source": [
    "for command in commands:\n",
    "    command_path = os.path.join(dataset_path, command)\n",
    "    # print(command_path)\n",
    "    files = os.listdir(command_path)\n",
    "    print(files)\n",
    "    recordings = []\n",
    "    for file in files:\n",
    "        file_path = os.path.join(command_path, file)\n",
    "        # print(file_path)\n",
    "        # we've moved one file: demo fider ac into a directory above: remeber to delete it\n",
    "        recording, sr = librosa.load(file_path, sr=None)\n",
    "        # print(recording, sr)\n",
    "        recordings.append(recording)\n",
    "    dataset[command] = recordings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract MFCC Features\n",
    "def extract_features(recording):\n",
    "    mfcc = librosa.feature.mfcc(y=recording, sr=sr, n_mfcc=13)\n",
    "    print(mfcc)\n",
    "    return mfcc.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define States and Build the Model\n",
    "n_states = 16 # the number of commands we have\n",
    "# model = hmm.GaussianHMM(n_components=n_states)\n",
    "model = hmm.GaussianHMM(n_components=4, covariance_type=\"diag\", n_iter=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Train the model on our data\n",
    "for command in commands:\n",
    "    X = np.vstack(\n",
    "        [extract_features(recording) for recording in dataset[command]]\n",
    "    ) # stacks arrays in sequence vertically: row-wise\n",
    "    model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-615.23425   -595.3319    -593.021     ... -599.8126    -598.0717\n",
      "  -599.38586  ]\n",
      " [  70.48137     84.05586     82.83789   ...   80.06057     81.20296\n",
      "    79.717804 ]\n",
      " [  34.989197    28.601088    23.122593  ...   27.707083    26.511002\n",
      "    25.149128 ]\n",
      " ...\n",
      " [  -3.3713937   -2.7822943   -3.1301765 ...   -8.360065    -5.44553\n",
      "    -5.4415436]\n",
      " [  -3.2295861   -3.7801251   -5.2786493 ...  -10.048229    -6.7899256\n",
      "    -5.8770657]\n",
      " [  -1.5549121   -2.9548712   -3.2821972 ...   -4.0869446   -3.0633922\n",
      "    -5.0855045]]\n"
     ]
    }
   ],
   "source": [
    "# test the model\n",
    "test_file_path = \"/home/ix502iv/Documents/Audio_Trad/HMM/custom_commands_copy/demo_fider_bilgileri/demo_fider_bilgileri.wav\"\n",
    "test_recording, sr = librosa.load(test_file_path, sr=None)\n",
    "test_features = extract_features(test_recording)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Command:  demo_fider_ac\n"
     ]
    }
   ],
   "source": [
    "scores = {}\n",
    "for command in commands:\n",
    "    score = model.score(test_features) # compute the log probability under the model\n",
    "    scores[command] = score\n",
    "\n",
    "predicted_command = max(scores, key=scores.get)\n",
    "print(\"Predicted Command: \", predicted_command)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45c48fb264bba0529b917885aa2fdf54bfc5ac58ac8ea30a57d1df6ad7c47fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
