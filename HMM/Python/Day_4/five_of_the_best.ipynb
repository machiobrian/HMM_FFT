{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the set of commands we want to classify with hmm\n",
    "import librosa\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "commands = [\"demo_fider_ac\", # 0\n",
    "            \"demo_fider_bilgileri\", # 1 \n",
    "            \"demo_fider_kapat\", # 2\n",
    "            \"nem_durumu\", # 3\n",
    "            \"gsm_durumu\" # 4\n",
    "            ]\n",
    "# since we have multiple .wav files in the dirs\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "dataset_path = \"/home/ix502iv/Documents/Audio_Trad/HMM/custom_commands\"\n",
    "for i, command in enumerate(commands):\n",
    "    # loop through each file in the folder\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.endswith(\".wav\"):\n",
    "            file_path = os.path.join(dataset_path, file) # there's need to have the full path to the file.\n",
    "            # print(file_path)\n",
    "            audio_data, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # print(\"File:\", filename)\n",
    "            # print(\"Sample rate:\", sr)\n",
    "            # print(\"Number of samples:\", len(audio_data))\n",
    "\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=audio_data,\n",
    "                sr=sr,\n",
    "                n_mfcc=13\n",
    "            )\n",
    "\n",
    "            data.append(mfcc.T)\n",
    "            labels.append(i)\n",
    "        \n",
    "# save the features and labels to a .npy file\n",
    "# save an array to a binary file\n",
    "np.save(\"data.npy\", np.vstack(data))\n",
    "np.save(\"labels.npy\", np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 24615 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ix502iv/miniconda3/envs/TensorFlow/lib/python3.10/site-packages/librosa/util/decorators.py:88: UserWarning: n_fft=2048 is too small for input signal of length=13\n",
      "  return f(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# extract the features from each file: mfcc features & save them along with their labels\n",
    "data = np.load(\"data.npy\", allow_pickle=True)\n",
    "data_reshaped = data.ravel()[:100]\n",
    "labels = np.load(\"labels.npy\", allow_pickle=True)\n",
    "print(len(labels), len(data), len(data_reshaped))\n",
    "\n",
    "# param for mfcc extraction\n",
    "n_mfcc = 15\n",
    "\n",
    "# preprocess the .wav file: extract mfcc features and save them with their labe\n",
    "features = []\n",
    "for i in range(len(data_reshaped)): # len(data) = 24615\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y = data[i],\n",
    "        sr = 44100,\n",
    "        n_mfcc= n_mfcc\n",
    "    )\n",
    "\n",
    "    features.append((mfcc.T, labels[i])) \n",
    "    # we run into a size error: IndexError: index 100 is out of bounds for axis 0 with size 100\n",
    "    # labels = 100, 24615 > 100 (actually 99: 0 to 99 = 100): soution reshape data to match 100:\n",
    "    # may reduce the accuracy of our model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45c48fb264bba0529b917885aa2fdf54bfc5ac58ac8ea30a57d1df6ad7c47fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
