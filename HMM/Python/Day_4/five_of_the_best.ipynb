{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the set of commands we want to classify with hmm\n",
    "import librosa\n",
    "import numpy as np \n",
    "import os\n",
    "\n",
    "commands = [\"demo_fider_ac\", # 0\n",
    "            \"demo_fider_bilgileri\", # 1 \n",
    "            \"demo_fider_kapat\", # 2\n",
    "            \"nem_durumu\", # 3\n",
    "            \"gsm_durumu\" # 4\n",
    "            ]\n",
    "# since we have multiple .wav files in the dirs\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "dataset_path = \"/home/ix502iv/Documents/Audio_Trad/HMM/custom_commands\"\n",
    "for i, command in enumerate(commands):\n",
    "    # loop through each file in the folder\n",
    "    for file in os.listdir(dataset_path):\n",
    "        if file.endswith(\".wav\"): # find any file that ends with .wav\n",
    "            file_path = os.path.join(dataset_path, file) # there's need to have the full path to the file.\n",
    "                                                         # for librosa's filepath\n",
    "            # print(file_path)\n",
    "            audio_data, sr = librosa.load(file_path, sr=None)\n",
    "\n",
    "            # print(\"File:\", filename)\n",
    "            # print(\"Sample rate:\", sr)\n",
    "            # print(\"Number of samples:\", len(audio_data))\n",
    "\n",
    "            # Extract the MFCC features\n",
    "            mfcc = librosa.feature.mfcc(\n",
    "                y=audio_data,\n",
    "                sr=sr,\n",
    "                n_mfcc = 40\n",
    "            )\n",
    "\n",
    "            data.append(mfcc.T) # mfcc transposed\n",
    "            labels.append(i)\n",
    "        \n",
    "# save the features and labels to a .npy file\n",
    "# simply saves an array to a binary file\n",
    "np.save(\"data.npy\", np.vstack(data))\n",
    "np.save(\"labels.npy\", np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(i, command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the features from each file: mfcc features & save them along with their labels\n",
    "data = np.load(\"data.npy\", allow_pickle=True)\n",
    "data_reshaped = data.ravel()[:100]\n",
    "labels = np.load(\"labels.npy\", allow_pickle=True)\n",
    "print(len(labels), len(data), len(data_reshaped))\n",
    "\n",
    "# param for mfcc extraction\n",
    "n_mfcc = 13\n",
    "\n",
    "# preprocess the .wav file: extract mfcc features and save them with their label\n",
    "features = []\n",
    "for i in range(len(data_reshaped)): # len(data) = 24615\n",
    "    mfcc = librosa.feature.mfcc(\n",
    "        y = data[i],\n",
    "        sr = 44100,\n",
    "        n_mfcc= n_mfcc\n",
    "    )\n",
    "\n",
    "    features.append((mfcc.T, labels[i])) \n",
    "    # we run into a size error: IndexError: index 100 is out of bounds for axis 0 with size 100\n",
    "    # labels = 100, 24615 > 100 (actually 99: 0 to 99 = 100): soution reshape data to match 100:\n",
    "    # may reduce the accuracy of our model\n",
    "np.save(\"features.npy\", np.array(features))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into training and the test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = np.load(\"features.npy\", allow_pickle=True)\n",
    "\n",
    "# the SPLIT\n",
    "X = np.array([f[0] for f in features]) # mfcc features\n",
    "y = np.array([f[1] for f in features]) # labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)\n",
    "np.save('X_train.npy', X_train)\n",
    "np.save(\"X_test.npy\", X_test)\n",
    "np.save(\"y_train.npy\", y_train)\n",
    "np.save(\"y_test.npy\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mdoelling time\n",
    "from hmmlearn import hmm\n",
    "\n",
    "# load the training set and their labels\n",
    "X_train = np.load(\"X_train.npy\", allow_pickle=True)\n",
    "y_train = np.load(\"y_train.npy\", allow_pickle=True)\n",
    "\n",
    "# define the number of states and features for the model\n",
    "n_states = 5 # the number of hidden states\n",
    "n_features = X_train.shape[2] # number of mfcc features : 15 == X_train.shape[2]\n",
    "\n",
    "\n",
    "# initialize the hmm model\n",
    "model = hmm.GaussianHMM(\n",
    "    n_components=n_states,\n",
    "    covariance_type=\"diag\",\n",
    "    n_iter=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model training: there is some reshaping of the input features to a 2D array with the shape\n",
    "# (-1, n_features)\n",
    "# model.fit(X_train.reshape(-1, n_features), lengths=[len(seq) for seq in X_train])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2D = np.reshape(X_train, (X_train.shape[0],-1))\n",
    "X_test_2D = np.reshape(X_test, (X_test.shape[0],-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from hmmlearn import hmm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the testing set of MFCC features and their labels\n",
    "X_test = np.load(\"X_test.npy\", allow_pickle=True)\n",
    "y_test = np.load(\"y_test.npy\", allow_pickle=True)\n",
    "\n",
    "# Define a list of candidate numbers of hidden states to try\n",
    "n_states_list = [3, 5, 7, 9]\n",
    "\n",
    "# Loop over the candidate numbers of hidden states and train a HMM model for each one\n",
    "best_accuracy = 0\n",
    "best_model = None\n",
    "\n",
    "for n_states in n_states_list:\n",
    "    # Initialize the HMM model\n",
    "    model = hmm.GaussianHMM(n_components=n_states, covariance_type=\"diag\", n_iter=100)\n",
    "\n",
    "    # Train the HMM model using the training set of MFCC features and their labels\n",
    "    # model.fit(X_train.reshape(-1, n_features), lengths=[len(seq) for seq in X_train])\n",
    "    model.fit(X_train_2D)\n",
    "\n",
    "    # Use the HMM model to predict the labels of the testing set of MFCC features\n",
    "    # y_pred = model.predict(X_test.reshape(-1, n_features), lengths=[len(seq) for seq in X_test])\n",
    "    y_pred = model.predict(X_test_2D)\n",
    "\n",
    "    # Compute the accuracy of the HMM model on the testing set of labels\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Update the best model and accuracy if the current model is better than the previous ones\n",
    "    if accuracy > best_accuracy:\n",
    "        best_accuracy = accuracy\n",
    "        best_model = model\n",
    "\n",
    "# Print the best accuracy and number of hidden states found\n",
    "print(\"Accuracy:\", best_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the new file to test\n",
    "filename = \"/home/ix502iv/Documents/Audio_Trad/HMM/custom_commands_copy/demo_fider_ac/demo_fider_ac.wav\"\n",
    "y, sr = librosa.load(filename, sr=None)\n",
    "mfcc = librosa.feature.mfcc(\n",
    "    y=y,\n",
    "    sr=sr,\n",
    "    n_mfcc=13,\n",
    "    n_fft=2048,\n",
    "    hop_length=512\n",
    ")\n",
    "\n",
    "# save the mfcc features to a file\n",
    "np.save(\"new_file.npy\", mfcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use viterbi algorithm to predict the most likely sequence for the features\n",
    "from hmmlearn import hmm\n",
    "# load the trained model\n",
    "model = hmm.GaussianHMM(\n",
    "    n_components=5,\n",
    "    covariance_type=\"diag\",\n",
    "    # n_features=13\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.startprob_ = np.array([1.0, 0.0, 0.0, 0.0, 0.0])\n",
    "model.transmat_ = np.array([\n",
    "    [0.5, 0.5, 0.0, 0.0, 0.0],\n",
    "    [0.0, 0.5, 0.5, 0.0, 0.0],\n",
    "    [0.0, 0.0, 0.5, 0.5, 0.0],\n",
    "    [0.0, 0.0, 0.0, 0.5, 0.5],\n",
    "    [0.0, 0.0, 0.0, 0.0, 1.0],\n",
    "])\n",
    "model.means_ = np.random.randn(5, 13)\n",
    "# model.covars_ = np.tile(np.identity(13), (5, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the MFCC features from the new .wav file\n",
    "filename = \"new_file.npy\"\n",
    "mfcc = np.load(filename)\n",
    "\n",
    "# Use the Viterbi algorithm to predict the most likely sequence of states\n",
    "logprob, state_sequence = model.decode(mfcc)\n",
    "print(\"Log probability: {:.2f}\".format(logprob))\n",
    "print(\"State sequence:\", state_sequence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "45c48fb264bba0529b917885aa2fdf54bfc5ac58ac8ea30a57d1df6ad7c47fba"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
